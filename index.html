<!DOCTYPE html>
<!-- Template by Quackit.com -->
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

    <title>Storm Damage</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS: You can use this stylesheet to override any Bootstrap styles and/or apply your own styles -->
    <link href="css/custom.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<style>
    .fblogo {
        display: inline-block;
        margin-left: auto;
        margin-right: auto;
        height: 30px; 
    }

    #images{
        text-align:center;
    }
    #carousel {
        width: 100%;
        height: 150px;
        background-color: #ff0000;
        
        overflow: visible;
        white-space:nowrap;
    }

    #carousel .slide {
        display: inline-block;
    }

    #h5 {
        font-size: 100px;
        text-align: center;
        width: 100%;
    }
    #h7 {
        font-size: 50px;
        text-align: center;
        width: 100%;
    }
    .horizontal_dotted_line{
        border-bottom: 1px dotted black;
        width: 90vw!important;
    } 
</style>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
        <div class="container">
            <!-- Logo and responsive toggle -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
            </div>
            <!-- Navbar links -->
            <div class="collapse navbar-collapse" id="navbar">
                <ul class="nav navbar-nav">
                    <li class="active">
                        <a href="#">Home</a>
                    </li>
                    <li class="active">
                        <a href="#introduction">Introduction</a>
                    </li>
                    <li class="active">
                        <a href="#eda">EDA</a>
                    </li>
                    <li class="active">
                        <a href="#classification">Classification</a>
                    </li>
                    <li class="active">
                        <a href="#regression">Regression</a>
                    </li>
                    <li class="active">
                        <a href="#conclusion">Conclusion</a>
                    </li>
                </ul>

            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

	<div class="jumbotron feature">
		<div class="container">
			<h1><span class="glyphicon glyphicon-cloud"></span> CS109a Final Project: Group 90</h1>
			<p>Predicting Damage of US Storms to Better Allocate Relief Resources</p>
            <p>By: George Hu, Josh Kuppersmith, Manav Khandelwal, and Evan Mackay</p>
            <p>Date: December 7, 2017</p>
		</div>
	</div>

    <!-- Content -->
    <div class="container">

        <!-- Heading -->
        <div class="row">
            <div class="col-lg-12">

                <div id = 'introduction'></div>
                <br></br>
                <h1 class="page-header">1. Introduction
                    <small>Motivation for this Project</small>
                </h1>
                <p>Over this past year, the United States has been ravaged by numerous natural disasters. From Hurricanes Irma and Harvey, to tornadoes in the Ohio Valley and a particularly costly hailstorm in Denver, to landslides on the Pacific coast, these disasters have taken a toll on communities across the country. Hurricane Harvey, the most costly hurricane ever recorded, alone accounted for $200 billion in damage on US soil, plus untold damage in the Caribbean. According to the National Center for Environmental Information, there were 14 storm events this year that cost the US over $1B. Note that the word “storm” includes hurricanes, droughts, fires, floods, hailstorms, and tornadoes, in addition to the thunderstorms traditionally associated with the word. With rapid climate change, these events may be becoming more common and more costly. Now, more than ever, it is crucial for federal, state, and local governments to utilize resources well to aid citizens in the wake of these storms. This problem, and a desire to help this effort for efficient resource allocation motivated our project. </p>

                <br></br>



                <div class="w3-container">
                  <h5>Storm Damage Images</h5>
                </div>

                <div class="w3-content w3-display-container"  style="width:75vw!important">

                <div class="w3-display-container mySlides">
                  <img class="img-responsive" src="images3/harvey.jpg" style="width:100%">
                  <div class="w3-display-bottomleft w3-large w3-container w3-padding-16 w3-black">
                    Hurricane Harvey (Houston)
                  </div>
                </div>

                <div class="w3-display-container mySlides">
                  <img class="img-responsive" src="images3/mudslide.jpg" style="width:100%">
                  <div class="w3-display-bottomright w3-large w3-container w3-padding-16 w3-black">
                    Pacific Coast Mudslide (CA)
                  </div>
                </div>

                <div class="w3-display-container mySlides">
                  <img class="img-responsive" src="images3/hail.jpg" style="width:100%">
                  <div class="w3-display-topleft w3-large w3-container w3-padding-16 w3-black">
                    Hail Storm (Midwest)
                  </div>
                </div>

                <div class="w3-display-container mySlides">
                  <img class="img-responsive" src="images3/flood.jpg" style="width:100%">
                  <div class="w3-display-topright w3-large w3-container w3-padding-16 w3-black">
                    Flooding (Alabama)
                  </div>
                </div>

                <div class="w3-display-container mySlides">
                  <img class="img-responsive" src="images3/tornado.jpg" style="width:100%">
                  <div class="w3-display-middle w3-large w3-container w3-padding-16 w3-black">
                    Tornado (Kansas)
                  </div>
                </div>

                <button class="w3-button w3-display-left w3-black" onclick="plusDivs(-1)">&#10094;</button>
                <button class="w3-button w3-display-right w3-black" onclick="plusDivs(1)">&#10095;</button>

                </div>

                
                <h1 class="page-header">1.1) Project Objectives</h1>

                <p>Our aim is to predict whether a storm will cause damage or not, and then accurately predict the amount of damage, in US dollars, that a storm will cause, so disaster response groups like FEMA know exactly how much resources to devote to relief. Our objective is to make this prediction immediately after a storm begins, before we are aware of how many people died or how much initial damage there was. This way, we can help groups like FEMA take action as quickly as possible. Other key agents like insurance companies and municipal governments would also benefit from such forecasts.</p>

                <h1 class="page-header">1.2) Data Source</h1>

                <p>We obtained our <a href="https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/">dataset from the United States National Oceanic and Atmospheric Administration (NOAA)</a>, which is a reputable governmental organization responsible for alerting the population about dangerous weather events. This organization is the leading source of weather information in the US, and we are confident that the data we are using is reliable since the NOAA, as one of the seven uniformed services, is held to the same procedural standards as the US Army, Navy, and Air Force. Furthermore, the NOAA is well-positioned to collect data because it has extensive resources. It oversees 120 Weather Forecast Offices (WFO’s) across the country and has access to all of the leading technology in the industry, such as weather balloons and weather planes. For the reasons outlined above, we believe strongly in the validity of the dataset we are using.</p>


                <p>NOAA has compiled a storm events database for every year since 1950. In the 1950’s, only several hundred observations were recorded each year, but in more recent times, over 40,000 storms have been documented annually. There were 42,971 logged storms in 2016, and 45,592 so far in 2017 through the end of November (the database is updated monthly). For each storm, the NOAA provides information about the storm type (thunderstorm, flood, hail storm, etc.), date, location, and much more. Please refer to the “Predictor Variables” and “Response Variables” sections below for a deeper dive into the storm recordings.</p>


                <p>Note that this database does not contain information about the most catastrophic of storms (large Atlantic hurricanes), but we believe that excluding these outlier data points is best for our modeling. To predict hurricane damage, we would likely have to build a completely separate model accounting for more information about trajectory and hurricane characteristics. Instead, we will only be comparing storms of relatively similar scale and caliber, which helps us create a stronger, more predictive model on the narrower dataset that we do have.</p>

                <h1 class="page-header">1.3) Key Variables
                    <small>Predictors and Response</small>
                </h1>
                <p>Predictor Variables: Our original dataset came with 40 potential predictor variables: 2 were indexing variables (e.g. EVENT_ID), 7 were related to date/time, and nearly all of the rest were categorical or ordinal variables such as EVENT_TYPE or STATE. We recognized that we should one-hot encode a number of these variables, so we conducted EDA on them, seeing whether there was potential significance in their effect on DAMAGE_PROPERTY/HAS_DAMAGE. This analysis is shown below in Figure _ (state of location), Figure _ (month of occurrence), and Figure _ (time of day).</p>
                <p>Response Variables: Our original dataset came with 2 response variables, DAMAGE_PROPERTY and DAMAGE_CROPS, both of which were measured in dollars ($). We decided to sum these two variables to create one response variable called DAMAGE_TOTAL, also measured in $. Finally, we created HAS_DAMAGE, a binary variable analogous to the IS_DELAYED variable from the midterm. We realized early on that DAMAGE_TOTAL would have a very skewed distribution. We describe how we dealt with this issue in our EDA/in the regression section.</p>
            </div>
        </div>

        <div class="row">
            <div class="col-lg-12">
                <h1 class="page-header">1.4) Introduction of Demographic Data
                </h1>
                <p>We recognized that to predict the cost of property damage a storm will create, information that merely encompassed location was not enough--we needed to know how many people live near the site of the storm, and also how much property they own. We hypothesized that the population density and average income of an area would both be positively correlated with the cost of damage and add to the predictive power of our model. We thus looked for external demographic data to incorporate into our existing dataset.</p>

                <p>In the <a href="http://pythonhosted.org/uszipcode/">“uszipcode” python package (credit: Sanhe Hu)</a>, we found all of the information that we were looking for. One of the package’s functionalities is taking latitude and longitude, which our original dataset provided, and returning a list of zipcodes within a certain mile-wide radius of those coordinates. We were able to take the first zipcode area listed, which was the closest one to the given coordinates by Euclidean distance, and grab the demographic data of that area as per the 2010 census. The final data categories we selected were population density, population, and average income per person (per household was not available). We were skeptical of this package at first since it was created by a third-party user, but we then validated the package on all four of our hometowns (Chicago, IL; Vero Beach, FL; Philadelphia, PA; and Los Angeles, CA) and confirmed that the results made sense. For instance, we checked to make sure that more wealthy areas around the cities we knew best had higher average incomes, and so on.</p>
            </div>
        </div>

        <div class="row">
            <div class="col-lg-12">
                <h1 class="page-header">1.5) Relevant Literature Review</h1>
                <p>In our literature review, we did not encounter any other works in which this specific NOAA storm events database was used, though we are sure that the database is an important part of the NOAA’s own storm prediction services. However, we were able to find other related works, of which the four most interesting/relevant are described below:</p>
                <p>1) Whipple, Sean David. “Predictive Storm Damage Modeling and Optimizing Crew Response to Improve Storm Response Operations.” DSpace@MIT, Massachusetts Institute of Technology, June 2014, dspace.mit.edu/handle/1721.1/90166.</p>
                <p>Whipple’s paper takes an approach that lends very well to the NOAA data we used, and we thus found it very helpful while tackling our own project. Whipple focuses on a very specific type of prediction, namely “Utilizing data mining and machine learning techniques [to] develop a model that gathers the data and applies a classification tree model to predict outages caused by weather.” In other words, he is trying to figure out under what conditions power outages are most likely to happen. Whipple, who was motivated by the disastrous aftereffects of Hurricane Sandy in 2012, focuses exclusively on the outages caused by hurricanes on the east coast. The results from this work gave us our first inkling that some sort of decision-tree based model would be most effective, which turned out to be true.</p>
                <p>2) Klemas, Victor V. “The Role of Remote Sensing in Predicting and Determining Coastal Storm Impacts.” Journal of Coastal Research, vol. 25, no. 6, Nov. 2009, pp. 1264–1275., doi:10.2112/08-1146.1.</p>
                <p>Klemas’s work was less relevant to our immediate project than Whipple’s, but it gave us several interesting ideas about future work we can do with the NOAA dataset. For instance, tracking weather conditions (temperature, humidity) with sensors, as Klemas does, would likely bolster our model by a significant amount. </p>
                <p>3) Bohannon, John. “Twitter Can Predict Hurricane Damage as Well as Emergency Agencies.” American Association for the Advancement of Science, 11 Mar. 2016, doi:10.1126/science.aaf4182.</p>
                <p>We found this piece of literature to be the most interesting one we encountered, and like Klemas’s paper, Bohannon’s provides several ideas for future work. Specifically, this paper takes a very modern approach to storm damage prediction--using social media to track what people are saying about the storm. We believe there is immense potential here, since natural language processing algorithms are quickly improving and could help organizations like FEMA gauge the severity of a storm without having to first send people to the site, which takes time and is also expensive.</p>
                <p>4) Costa, Katrina and Miranda Peterson. “Extreme Weather, Extreme Costs”. Center for American Progress, 27 Oct. 2017., https://www.americanprogress.org/issues/green/reports/2017/10/27/441382/extreme-weather-extreme-costs/</p>
                <p>This piece discussed that, often times, the demographics of the location in which a storm event takes place are more important to predicting damage than the intensity or severity of the event. For instance, a minor thunderstorm in a densely populated area is likely to cause more damage than a strong tornado in an uninhabited area. This article pointed out how information like median household income can make for useful predictors, and was one of the main factors in leading us to incorporate the demographic data in the uszipcode package into our dataset.</p>
            </div>
        </div>

        <div id = 'eda'></div>
        <br></br>

        <!-- Heading -->
        <div class="row">
            <div class="col-lg-12">
                <h1 class="page-header">2. Exploratory Data Analysis
                    <small>Key Findings</small>
                </h1>
                <p>The first step in our analysis of storms in the US is to create some visuals in order to gain some intuition for what our data looks like, and which factors may be predictive for storm damage. Here are some key visuals, and explanations of the main findings:</p>
            </div>
        </div>
        <!-- /.row -->

        <br></br>
        <!-- Feature Row -->
        <h7 style="font-size: 22px!important; text-decoration: underline">2.1) Storm Type Exploration</h7>

        <div class="row">
            <article class="col-md-4 article-intro" style="width:75vw!important">
            <br></br>
                <p>The first predictor we were curious to explore was storm type, since our previous experiences (e.g. hearing about storms on the news) led us to believe that tornados and floods were the most costly types of storms. We wanted to confirm this hypothesis, as well as others, about storm type, and so we generated plots showing (1) which storm type accounted for the highest number of damage-causing storms and (2) which storm type caused the most damage (in dollars) on a per-storm basis. These two plots are displayed below.</p>

                <img class="img-responsive" src="images3/freq_damage_storm_type.png" alt="">
                <br></br>
                <img class="img-responsive" src="images3/ave_damage_storm_type.png" alt="">
                <br></br>
                
                <p>Contrary to what we believed, thunderstorm winds accounted for the highest number of damaging storms, with floods (and flash floods) accounting for the second highest number. As we predicted, floods caused the most damage per storm of all of the storm types. After conducting qualitative research, our logical conclusions for these findings are that tornadoes do not cause a lot of damage because they tend to take place in sparsely populated areas in the Midwest (particularly in a region colloquially called “Tornado Alley”), and also that winds can cause a lot of damage by downing trees and power lines. Our reasoning for the damaging nature of floods is that replacing flooring can be very expensive (upwards of thousands of dollars per home).</p>
            </article>
        </div>

        <div class="horizontal_dotted_line"></div>
        <div class="horizontal_dotted_line"></div>

        <br></br>
        <h7 style="font-size: 22px!important; text-decoration: underline">2.2) Location Data Exploration</h7>

        <div class="row">
            <article class="col-md-4 article-intro" style="width:75vw!important">
            <br></br>
                <p>Diving deeper into our dataset, the next thing we noticed was how much information about location the dataset contained. From time zone to state to municipality (WFO), to begin_long, begin_lat, end_long, and end_lat, we counted 17 potential predictors in total that corresponded to locational data. To gain better intuition about them, and also figure out which ones to drop to avoid overfitting on location, we checked which predictors had clear correlations with the frequency of damage-causing storms. In the three figures below, we display which timezones, states, and municipalities recorded the most damage-causing storms. We decided that each of these three predictors were important and should be kept in our model. We describe which predictors we dropped in the next section (Dropping Predictors).</p>
                <br></br>
                    <img class="img-responsive" src="images3/freq_damage_timezone.png" alt="">
                <br></br>
                    <img class="img-responsive" src="images3/freq_damage_state.png" alt="">
                <br></br>
                    <img class="img-responsive" src="images3/freq_damage_wfo.png" alt="">
                <br></br>

                <p>Above, we see that most damage-causing storms take place in the Central and Eastern Time Zones. We were surprised that there were so many more storms here compared with the Pacific and Mountain Time Zones, but these results ultimately make sense because thunderstorms accounted for the highest number of damaging storms, and most thunderstorms take place on the east coast where it is more humid than the west coast. Next, we concluded that state was a promising predictor since some states have many more storm recordings than others. For instance, Pennsylvania had the most storms with over 1,500 storms while Oregon had fewer than 30 storms. We made the same conclusion for WFO (Municipality), with some municipalities having much more storms than others. The municipality with the highest damaging storm count by far is JAN, which corresponds to Jackson, Mississippi. Mississippi was the state with the second highest number of damaging storms, so this result made sense.</p>
            </article>
        </div>

        <div class="horizontal_dotted_line"></div>
        <div class="horizontal_dotted_line"></div>

        <br></br>
        <h7 style="font-size: 22px!important; text-decoration: underline">2.3) Temporal Data Exploration</h7>

        <div class="row">

            <article class="col-md-4 article-intro" style="width:75vw!important">

                <br></br>
                <p>Finally, we checked temporal information like month and time of day, both of which had a significant impact on the frequency of damaging storms.</p>
                <br></br>
                    <img class="img-responsive" src="images3/freq_damage_month.png" >
                <br></br>
                    <img class="img-responsive" src="images3/freq_damage_hour.png" >
                <br></br>

                <p>As we can see, more storms take place during the summer months, which leads us to believe that thunderstorms are more damaging than snowstorms, etc. Also, more storms take place in the afternoon and evening hours, which is surprising since storms take place around the clock. Our conclusion from this result is that people tend to log storm damage in the waking hours of the day. More importantly than the logical reasoning behind these temporal predictors, we confirm that we want to keep them as predictors in our models. </p>
            </article>
        </div>

        <div class="horizontal_dotted_line"></div>
        <div class="horizontal_dotted_line"></div>

        <br></br>
        <h7 style="font-size: 22px!important; text-decoration: underline">2.4) Map Visualizations</h7>

        <!-- Feature Row -->
        <div class="row">

            
            <article class="col-md-4 article-intro">
                <h3>
                <a>US Storm Types</a>
                </h3>
                    <img class="img-responsive" src="images3/storm_type.png" alt="">
                <br></br>
                <p>Shows storm types in our dataset. The legend lists storm freq., and we see trends like Marine Thunderstorms all along the Atlantic Coast and debris flow (mudslides) on the Pacific Coast. Hail, Thunderstorms, and Floods are widespread, but certainly show some clustering and regional differences.</p>
            </article>
            
            <article class="col-md-4 article-intro">
                <h3>
                <a>Storm Distribution</a>
                </h3>
                    <img class="img-responsive" src="images3/heatmap.png" alt="">
                <br></br>
                <p>This is a Google Maps heatmap showing distribution of all storm data across the US. It is important to see that our storms are concentrated East of the Rockies (perhaps simply due to reporting). Additionally, there is a concentration of storms along the Gulf of Mexico, and in Tornado Alley.</p>
            </article>
            
            <article class="col-md-4 article-intro">
                <h3>
                <a>Damage Likelihood</a>
                </h3>
                    <img class="img-responsive" src="images3/damage_likelihood.png" alt="">
                <br></br>
                <p>This Carto images shows likelihood of a storm causing monetary damage. Dark squares means that most storms cause some damage. We see clear regional trends in where damage is caused like in the Ohio River Valley and along the SW southern border. Clearly, damage has spatial trends, which makes the other graphs here clearly relevant to our predictive power.</p>
            </article>
        </div>


        <div class="horizontal_dotted_line"></div>
        <div class="horizontal_dotted_line"></div>

        <br></br>
        <h7 style="font-size: 22px!important; text-decoration: underline">2.5) Demographic Data Exploration</h7>
        <br></br>
        <br></br>
        <div class="row">

            <article class="col-md-4 article-intro" style="width:75vw!important">

                <a style="text-align: center!important">
                    <img class="img-responsive" src="images3/demographic.png" style="margin: auto" >
                </a>
                <br></br>
                <a style="text-align: center!important">
                    <img class="img-responsive" src="images3/pop_density.png" style="margin: auto; width: 600px;
                    height: auto!important" >
                </a>
                <br></br>

                <p>The purpose of the first plot above was to confirm that we needed to normalize the data, particularly the demographic data, which was extremely right-skewed. In addition, the population density map confirms that our demographic data is a solid source, as it looks correct based on what we know about population in the US.</p>
            </article>
        </div>

        <div class="horizontal_dotted_line"></div>
        <div class="horizontal_dotted_line"></div>


        

        <div class="horizontal_dotted_line"></div>
        <div class="horizontal_dotted_line"></div>
        <br></br>
        <h7 style="font-size: 22px!important; text-decoration: underline">2.6) Monetary Response Distribution</h7>
        <br></br>
        <div class="row">


            <article class="col-md-4 article-intro" style="width:90vw!important">
                    <img class="img-responsive" src="images3/normalize.png" >
                <br></br>

                <p>The graphs above are a histogram of the DAMAGE_TOTAL variable (left), a histogram of the transformed DAMAGE_TOTAL variable using natural logarithm (center), and a histogram of the transformed DAMAGE_TOTAL variable conditioning on whether there was any damage at all (right). The normality exhibited in the third graph lets us know that if we build a classification model to predict any damage, and then regress conditional on that, we could have success predicting the log of DAMAGE_TOTAL because our response would be symmetric.</p>
            </article>
        </div>

        <div id = 'classification'></div>
        <br></br>

        <div class="row">
            <div class="col-lg-12">
                <h1 class="page-header">3. Modeling Damage or Not
                    <small>Classification and Results</small>
                </h1>
                <p>The first modeling step for this project is to classify whether a storm causes damage. Although this step does not directly help to administer aid, it is a step in that direction. To have a basic intuition of whether or not a storm causes damage is a step toward understanding the storm, and helps us learn which storms to focus on.</p>
                <br></br>
                <h7 style="font-size: 22px!important; text-decoration: underline">3.1) Initial Data Intuition</h7>
                <br></br>
                <p>The data contained a ratio of no damage to damage of about 2:1. This is not too far from the ideal case of 1:1 in most classification settings. It was decided that a basic logistic ordinary least squares regression model would be run. What this does is relate the log of the probability of a case having damage to a linear combination of the predictors. This basic model had an accuracy of near 0.75, well above the most naive approach which would have about 66% accuracy if all cases were predicted to not have damage. The model has true negative of 0.86 and true positive of 0.55 and an area under the curve (AUC) of .81. </p>
                <p>An interpretation of this AUC is the the expectation that a uniformly drawn random positive is ranked before a uniformly drawn random negative. In layman’s terms, AUC represents the tradeoff between allowing for more false positive and getting more true positives, and a higher AUC indicates a better model; an AUC of 1 represents the perfect classifier, while predicting all 0s (all false) would lead to an AUC of .5.</p>
                <br></br>
                <h7 style="font-size: 22px!important; text-decoration: underline">3.2) Predictor Selection</h7>
                <br></br>
                <p>Now that this baseline had been established, we looked to curate a better set of predictors for future models. First, more predictors were added to the logistic regression model, such as demographic information about the county where the weather event occurred, such as median household income, population density, and population size.</p>
                <p>One-hot encoding counties was not considered due to the possibility of overfitting with so many counties in the USA, but the nearest WFO weather station was recorded as a one-hot encoded set of variables to gain more information on place beyond just state.</p>
                <p>Next, complex effects were added such as interaction terms. The “Magnitude” of the weather event means different things for different types of weather events; for a hail storm, it is the size of the hail, for a thunderstorm it might be the maximum sustained wind, etc. To address this, the interactions of the variable magnitude and the one-hot encoded weather event types were included in the model. Pairwise interactions between income, population density, and population were also included. </p>
                <p>The predictive power increased dramatically, with a logistic regression on these set of predictors producing a model with an accuracy of 82% with an AUC of .896, much better than the baseline.</p>
                <br></br>
                <h7 style="font-size: 22px!important; text-decoration: underline">3.3) Trial and Error</h7>
                <br></br>
                <p>Next, the model building process pivoted direction; now instead of manipulating the predictors, the same predictors were used but for other families of models. We tried a few approaches that were not convincing, like k-Nearest Neighbors (k-NN) and Discriminant Analysis. k-NN is a non-parametric procedure, meaning that it does not rely on any underlying statistical assumptions about the data; it uses Euclidean distance to select the most similar observations based on the predictors, and then averages their response variables to make a prediction. k-NN had an AUC of .892, slightly worse than logistic regression.</p>
                <p>Quadratic discriminant analysis (QDA) and linear discriminant analysis (LDA) were also completed, which make assume normality within the predictors and use Bayes Rule to classify the response from the predictors. These did not improve the model, which was expected as the quantitative predictors were shown in EDA to be highly skewed; standardization helped but not enough.</p>
                <p>We also used the AdaBoost (Adaptive Boosting) procedure, which uses a procedure called gradient descent to iteratively train models (subsequent learners are changed in favor of observations misclassified by previous classifiers.). Thus, if not properly limited, AdaBoost can overfit massively, but we used cross-validation to choose its hyperparameters like the number of trees and the maximum depth of each model within the “bag.” This outperformed the previous models with a test accuracy of .901 and an AUC of .94.</p>
                <br></br>
                <h7 style="font-size: 22px!important; text-decoration: underline">3.4) Choosing a Model</h7>
                <br></br>
                <p>We ended up choosing the <b>Random Forest classifier</b> as our final model. We’ll get into why, but first, what is a Random Forest model? It based on the idea of a Decision Tree classifier, which uses a greedy algorithm to pick threshold values for predictors and assigns observations to a particular class based on those thresholds. The tree “splits,” or chooses a new threshold value for a particular predictor, in a way that maximizes the purity: each new region defined by the classification boundaries should be made up almost exclusively of one class.</p>
                <p>Essentially, if we have k classes, we choose predictor j and threshold t_j that minimizes the average Gini Index over all regions, where the Gini index for region i is:</p>
                <img class="img-responsive" src="images3/gini.png" style="margin: auto" >
                <p>This is equivalent to a "soft" maximum for purity larger numbers (when squared) will dominate smaller numbers. We iterate over the predictor set, and only terminate the splitting when we reach a stopping criterion; common stopping conditions are a maximum depth of the tree, a minimum number of observations in each region, etc.</p>
                <p>To create sufficiently complex decision boundaries, however, the tree needs to be very deep which leads to overfitting and high variance. To avoid this problem, we use the Random Forest procedure, which re-samples our data using a bootstrap approach and fits a number of Decision Tree models, averaging the results (using majority vote for classification) to make a prediction.</p>
                <p>However, these trees would tend to be highly correlated because a couple of really useful predictors would be chosen each time for the splits; we showed in lecture that for $B$ identically but not independently distributed variables with pairwise correlation rho and variance sigma-squared, the variance of their mean would be:</p>
                <img class="img-responsive" src="images3/rho.png" style="margin: auto" >
                <p>Therefore, more trees can only reduce the second term and not the first, so without any limitations, there would be high correlation among trees and thus fail to solve high variance/over-fitting problem. To fix that, the Random Forest algorithm randomly selects a subset of the predictors that can be used at each split so that the trees will not all be the same.</p>
                <p>Thus, we expected the Random Forest algorithm to perform quite well especially because there were a number of predictors that we expected to be important in classifying the response. We used cross-validation to simultaneously choose the optimal set of hyperparameters, namely the number of predictors for each split, the maximum depth of each tree, and the number of trees to fit for the model.</p>
                <p>Ultimately, the Random Forest model did not disappoint; it had the <b>best test accuracy, .91</b>, and the <b>best AUC, .96</b>. However, beyond just excellent performance out of sample, it gave us a sense of predictor importance based on how they contributed to minimizing the Gini Index discussed above. According to our model, the most important predictors were a combination of a few things: interaction terms between MAGNITUDE and different EVENT_TYPE categories, demographic data (POPULATION, DENSITY, and HH_INCOME) and their pairwise interaction, specific months, and specific large municipalities (WFO categories).</p>
                <br></br>
            </div>
        </div>

        <div id = 'regression'></div>
        <br></br>

        <div class="row">
            <div class="col-lg-12">
                <h1 class="page-header">4. Modeling Monetary Damage
                    <small>Regression</small>
                </h1>
                <p></p>
                <p>Beyond classifying whether or not there is damage to something, we also want to predict the dollar amount of damage: DAMAGE_PROPERTY, the estimated amount of property damage caused by the storm (conditional on HAS_DAMAGE = 1). This step is crucial for making recommendations on the proper amount of aid required for storm relief. Because this amount is very right skewed in the data, a log transformation was conducted which made the response more symmetric (to see this graphically, look at Figure 9 in the EDA section). Models were run to predict this log transformed variable, which can easily be transformed back to obtain the actual damage prediction when used in the future.</p>
                <br></br>
                <h7 style="font-size: 22px!important; text-decoration: underline">4.1) Linear</h7>
                <br></br>
                <p>First, we tried ordinary least squares linear regression. Given a set of p predictors, linear regression fits the following model (where Y is the response and X is a predictor):</p>
                <img class="img-responsive" src="images3/linear.png" style="margin: auto" >
                <p>The model chooses coefficients, the beta values, as to minimize the sum of squared errors (where the “hat” indicates a fitted value from the regression model):</p>
                <img class="img-responsive" src="images3/cost.png" style="margin: auto" >
                <p>Using a limited set of predictors, basic ordinary least squares regression model yielded a R2 of 0.43 in the testing set. This served as our baseline model. Once interaction and polynomial terms were included, the <b>test R2 increased to 0.46</b>, indicating that those predictors were useful (we did not conduct extensive t-based inference because this was not the final model). We want a higher R2 for our model, as it represents the amount of variance in the response explained by the model. The statistic is given by the following equation:</p>
                <img class="img-responsive" src="images3/r2.png" style="margin: auto" >
                <br></br>
                <p>This model was then evaluated for whether it is violating assumptions of ordinary least squares regression, which include normality, constant variance, and linearity of the residuals. To check these we plotted a histogram of the residuals and a residual scatter plot (against fitted values):</p>
                <br></br>
                <img class="img-responsive" src="images3/residual_plot.png" style="margin: auto; width: 600px;
                    height: auto!important" >
                    <br></br>
                <img class="img-responsive" src="images3/residual_hist.png" style="margin: auto; width: 600px;
                    height: auto!important" >
                    <br></br>
                <p>None of our assumptions seem to be violated. There is no evidence of non-linearity or heteroscedasticity (non-constant variance), and the residual histogram is fairly symmetric so we are comfortable with the normality assumption. This suggests that our OLS model is statistically rigorous.</p>
                <p>LASSO and Ridge regularization did not improve our model, which is understandable because there was no evidence of overfitting (and these shrinkage methods bias our coefficient estimates mathematically).</p>
                <br></br>
                <h7 style="font-size: 22px!important; text-decoration: underline">4.2) Random Forest</h7>
                <br></br>
                <p>We tried k-NN regression, but it did not perform well out of sample. The model we decided to use for predicting the amount of was a Random Forest Regressor, which is very similar to the Random Forest Classifier, but now rather than classifying the response based on the majority in a region (based on predictors), the model averages the response values of observations in a region and uses that as the prediction. In addition, the trees upon which the Random Forest is built minimize a new function, the sum of the standard deviation in each region.</p>
                <p>We again used cross-validation to choose the hyperparameters of the model, and were able to obtain a <b>test R2 of .773</b>, a significant upgrade from OLS. Again, we were not surprised that Random Forest was so adept at making predictions because of the fact that there were a number of important features rather than just a few which would cause each tree to be biased.</p>
                <br></br>
                <h7 style="font-size: 22px!important; text-decoration: underline">4.3) Model Choice</h7>
                <br></br>
                <p>In the end, we choose this random forest regressor as our final model for this regression problem. Although by selecting the random forest, we sacrifice some interpretability of our model, as we will explain below, we can still take some key insights away from gini coefficients for this model. Most importantly, the RF regression performs much better than our best OLS model. At the end of the day, this model is built to provide aid for people at risk of costly storm damage (or even at risk for their lives), so we feel that performance is the most important factor in regression model selection. By selecting the most accurate regressor, this model could do the most to help people in difficult and dangerous times.</p>
            </div>
        </div>

        <div id = 'conclusion'></div>
        <br></br>

        <div class="row">
            <div class="col-lg-12">
                <h1 class="page-header">5. Conclusion
                    <small>Findings and Recommendations</small>
                </h1>
                <h7 style="font-size: 22px!important; text-decoration: underline">5.1) Conclusion and Key Results</h7>
                <br></br>
                <p>If you take anything away from what you’ve read above, it’s that it is certainly possible to predict whether a storm will cause damage and if so, how much damage will occur. Using the Random Forest procedure, we were able to achieve an AUC of .96 for the classification model and an out-of-sample R2 of .77 for the regression model. Both are impressive metrics, especially given the limited parameter set we chose to operate with. It shows that certain ex-ante information can be used to help local governments, aid agencies, and insurance companies prepare for weather events.</p>
                <p>Delving deeper, the models we explored also gave us specific insights that can potentially assist those same agents. On one hand, we were able to get a better sense of which predictors were most useful for classifying damage or no damage, and which variables were the most predictive in estimating the amount of damage. Below we see the 30 most important predictors for the Random Forest classifiers (regression on the left, classification on the right) in terms of their contribution to the purity of the decision boundaries, based on the Gini Index metric discussed above:</p>
                <br></br>
                <h7 style="font-size: 22px!important; text-decoration: underline">5.2) Recommendations for Storm Aid</h7>
                <br></br>
                <p>Delving deeper, the models we explored also gave us specific insights that can potentially assist those same agents. On one hand, we were able to get a better sense of which predictors were most useful for classifying damage or no damage, and which variables were the most predictive in estimating the amount of damage. Below we see the 30 most important predictors for the Random Forest classifiers (regression on the left, classification on the right) in terms of their contribution to the purity of the decision boundaries, based on the Gini Index metric discussed above:</p>
                <br></br>
                <div id="images">
                    <a><img class="fblogo" border="0" src="images3/pred1.png" style="width: 400px;
                    height: auto!important" /></a>
                    <a><img class="fblogo" border="0" src="images3/pred2.png" style="width: 400px;
                    height: auto!important" /></a>
                </div>​
                <br></br>
                <p>As we can see, they overlap significantly. THUNDERSTORM_WIND’s main effect and interaction with MAGNITUDE were important in both models, as were a number of municipalities. On top of that, there are several EVENT_TYPE indicators (like “Flash Flood”) and MONTH indicators (like June) that appear on both. Finally, the demographic variables (POPULATION, HH_INCOME, and DENSITY) are very important predictors, whether as main effects, polynomial effects, or interaction effects. This signals that understanding the type of storm, the demographic data of the affected area, and the time of year/part of the country are all very important for key agents.</p>
                <p>We also use the OLS model to gain some intuition as to how certain predictors affect the amount of damage caused. We found that the “Marine Strong Wind” storm type had the largest coefficient of any predictor, meaning that it causes the most damage of any storm type when controlling for other variables. On the other hand, the “Thunderstorm Wind” storm type had the smallest (most negative) coefficient of any predictor, meaning that it causes the least damage of any storm type when controlling for other variables. We also see that flood-type events cause some of the most damage, meaning that local governments and insurance agencies should be wary of them. Beyond the EVENT_TYPE indicators, certain municipalities and months tend to be associated with more or less damage, which are also pieces of information that these agents can take into account. Interestingly, and this could have significant policy implications, we found that household income and population are negatively correlated with damage (in the OLS model, at least); this indicates poorer and less densely populated areas suffer more damage when controlling for other factors, like the ferocity and type of the storm.</p>
                <br></br>
            </div>
        </div>
        <!-- /.row -->

        <div class="row">
            <div class="col-lg-12">
                <h1 class="page-header">6. What's Next?
                    <small>Possibilities for Future Work</small>
                </h1>
                <p>In this project, we were pleased with the way our final model predicted for storm damage across many different types of storms as well as over a large geographic region. However, there is always work to be done to improve storm prediction. One type of storm that this model fails to consider is hurricanes, because they do not appear in this dataset. Hurricanes are arguably the most significant type of storm to model since they cause so much destruction and damage. However, hurricanes are on a whole different scale from the other types of storms that we are analyzing in this project. In order to model hurricanes, we would have to find hurricane data, and build a whole new model to analyze hurricanes separately. It would not make sense to classify as Damage-Causing or Not, because almost all hurricanes cause damage. Instead, we could determine a threshold for damage where a hurricane becomes catastrophic, and classify if a storm will be a Catastrophe or Not before regressing to predict total damage. Similar to this project, we would attempt to pull in data about the trajectory and cities/geographical features in the way. If we took hurricane data and built a new model similar to this one, but specific to hurricane prediction, we could greatly improve resource allocation.</p>
                <p>Another possible improvement we could make to our model is adding information about weather conditions into our database. Based on what we know about thunderstorms and hurricanes, we expect that certain conditions (certain temperatures, certain humidities) are more conducive to damaging storms, and this is a hypothesis we would want to test. We could incorporate this weather information by using a package similar to the zipcode one we accessed to pull demographic data. Given more time, this is certainly an extension of this project that we would explore in an effort to improve our classifications and regressions.</p>
                <p>Additionally, we originally thought about modeling a regression to predict human injuries or deaths from storms. Because the data for this is so sparse (very few storms injure or kill people), we decided that damage would be a more practical and impactful response variable, but a future model of injury or death could certainly add intuition to how harmful a storm is, and aid storm response.</p>
                <p>Last but not least, we see great potential in working with the NOAA to improve their storm events database. Over the course of this project, we determined which variables are the most helpful when trying to predict storm damage. We would recommend the NOAA to focus R&D funds on improving the technology that collects information for these variables. For instance, we found that the magnitude of a thunderstorm (the interaction term) is a very powerful predictor, so we would advise the NOAA to improve their thunderstorm tracking devices.</p>
            </div>
        </div>
        <!-- /.row -->

    </div>
    <!-- /.container -->
	
	<footer>

        
        <div class="small-print">
        	<div class="container">
        		<p><i>Thanks for reading! We hope you enjoyed.</i></p>
        	</div>
        </div>

        <div class="small-print">
            <div class="container">
                <b style="text-align:center!important">Database and Software Accessed</b>
                <p></p>
                <p>1) <a href="https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/">NOAA Storm Events Database</a>: This database provided us with our core data about storm type, storm location, damage caused, and much more. Please see the “Data Source” section for more about this database./</p>
                <p>2) <a href="http://pythonhosted.org/uszipcode/">uszipcode 0.1.3 Python Package || Credit: Sanhe Hu</a>: This database provided us with our additional demographic information such as population, population density, and average income per person. Please see the “Introduction of Demographic Data” section for more about this package and how we utilized it.</p>
                <p>3) Carto and Google Maps API: Carto is an online mapping tool that allows users to import data and display it on maps with a number of built in features, and we used this for several EDA maps. The Google Maps API was used for a webapp that takes in storm data and plots in on a satellite map as a heatmap. This was also used for EDA.</p>
            </div>
        </div>
        <div class="small-print">
            <div class="container">
                <b style="text-align:center!important">Works Referenced</b>
                <p></p>
                <p style="text-decoration: underline">NOAA and FEMA</p>
                <p>“About Our Agency.” National Oceanic and Atmospheric Administration, www.noaa.gov/about-our-agency.</p>
                <p>Achenbach, Joel. “Only 26 Percent of Hurricane Harvey Survivors Had FEMA Aid Request Approved, Survey Finds.” The Washington Post, WP Company, 5 Dec. 2017, www.washingtonpost.com/news/post-nation/wp/2017/12/05/only-26-percent-of-hurricane-harvey-survivors-have-had-fema-aid-request-approved-survey-finds/?utm_term=.f265c29371a7.</p>
                <p style="text-decoration: underline">Hailstorms</p>
                <p>Svaldi, Aldo. Hailstorm That Hammered West Metro Denver May 8 Is Costliest Ever for Colorado. The Denver Post, 16 June 2017, www.denverpost.com/2017/05/23/hailstorm-costliest-ever-metro-denver/.</p>
                <p style="text-decoration: underline">Tornadoes</p>
                <p>Dolce, Chris. “2017 Hurricane Season Produces Most Reported Tornadoes in Nearly a Decade.” The Weather Channel, 8 Nov. 2017, weather.com/storms/hurricane/news/2017-11-08-tornadoes-hurricane-season-2017-harvey-irma-nate-cindy-philippe.</p>
                <p style="text-decoration: underline">Flooding</p>
                <p>Fessenden, Ford, et al. “Water Damage From Hurricane Harvey Extended Far Beyond Flood Zones.” The NYT Online, The New York Times, 1 Sept. 2017, www.nytimes.com/interactive/2017/09/01/us/houston-damaged-buildings-in-fema-flood-zones.html.</p>
                <p style="text-decoration: underline">Thunderstorms</p>
                <p>“Thunderstorm Basics.” NOAA National Severe Storms Laboratory, NOAA, www.nssl.noaa.gov/education/svrwx101/thunderstorms/.</p>
                <p>Fortier, Marc, and Chris Emma. “Violent Thunderstorms Cause Damage North of Boston.” NECN Online, New England Cable News, 28 July 2017, www.necn.com/news/new-england/Powerful-Storm-Causes-Damage-Across-Greater-Boston-428268223.html.</p>
                <p style="text-decoration: underline">Literature Review</p>
                <p>Bohannon, John. “Twitter Can Predict Hurricane Damage as Well as Emergency Agencies.” American Association for the Advancement of Science, 11 Mar. 2016, doi:10.1126/science.aaf4182.</p>
                <p>Costa, Katrina and Miranda Peterson. “Extreme Weather, Extreme Costs”. Center for American Progress, 27 Oct. 2017., https://www.americanprogress.org/issues/green/reports/2017/10/27/441382/extreme-weather-extreme-costs/</p>
                <p>Klemas, Victor V. “The Role of Remote Sensing in Predicting and Determining Coastal Storm Impacts.” Journal of Coastal Research, vol. 25, no. 6, Nov. 2009, pp. 1264–1275., doi:10.2112/08-1146.1.</p>
                <p>Whipple, Sean David. “Predictive Storm Damage Modeling and Optimizing Crew Response to Improve Storm Response Operations.” DSpace@MIT, Massachusetts Institute of Technology, June 2014, dspace.mit.edu/handle/1721.1/90166.</p>
            </div>
        </div>
	</footer>

	
    <!-- jQuery -->
    <script src="js/jquery-1.11.3.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>
	
	<!-- IE10 viewport bug workaround -->
	<script src="js/ie10-viewport-bug-workaround.js"></script>
	
	<!-- Placeholder Images -->
	<script src="js/holder.min.js"></script>
    <script>
    var slideIndex = 1;
    showDivs(slideIndex);

    function plusDivs(n) {
      showDivs(slideIndex += n);
    }

    function showDivs(n) {
      var i;
      var x = document.getElementsByClassName("mySlides");
      if (n > x.length) {slideIndex = 1}    
      if (n < 1) {slideIndex = x.length}
      for (i = 0; i < x.length; i++) {
         x[i].style.display = "none";  
      }
      x[slideIndex-1].style.display = "block";  
    }
    </script>
	
</body>

</html>
